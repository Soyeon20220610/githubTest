{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrCC2qkUpAaD"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/https-deeplearning-ai/tensorflow-1-public/blob/master/C2/W3/ungraded_lab/C2_W3_Lab_1_transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bT0to3TL2q7H"
      },
      "source": [
        "# Ungraded Lab: Transfer Learning\n",
        "\n",
        "In this lab, you will see how you can use a pre-trained model to achieve good results even with a small training dataset. This is called _transfer learning_ and you do this by leveraging the trained layers of an existing model and adding your own layers to fit your application. For example, you can:\n",
        "\n",
        "1. just get the convolution layers of one model\n",
        "2. attach some dense layers onto it\n",
        "3. train just the dense network\n",
        "4. evaluate the results\n",
        "\n",
        "Doing this will allow you to save time building your application because you will essentially skip weeks of training time of very deep networks. You will just use the features it has learned and tweak it for your dataset. Let's see how these are done in the next sections."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qvrr8pLRzJMV"
      },
      "source": [
        "**IMPORTANT NOTE:** This notebook is designed to run as a Colab. Running the notebook on your local machine might result in some of the code blocks throwing errors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-12slkPL6_JH"
      },
      "source": [
        "## Setup the pretrained model\n",
        "\n",
        "You will need to prepare pretrained model and configure the layers that you need. For this exercise, you will use the convolution layers of the [InceptionV3](https://arxiv.org/abs/1512.00567) architecture as your base model. To do that, you need to:\n",
        "\n",
        "1. Set the input shape to fit your application. In this case. set it to `150x150x3` as you've been doing in the last few labs.\n",
        "\n",
        "2. Pick and freeze the convolution layers to take advantage of the features it has learned already.\n",
        "\n",
        "3. Add dense layers which you will train.\n",
        "\n",
        "Let's see how to do these in the next cells."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VqhFEK2Y-PK"
      },
      "source": [
        "First, in preparing the input to the model, you want to fetch the pretrained weights of the `InceptionV3` model and remove the fully connected layer at the end because you will be replacing it later. You will also specify the input shape that your model will accept. Lastly, you want to freeze the weights of these layers because they have been trained already."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xJZ5glPPCRz"
      },
      "outputs": [],
      "source": [
        "# Download the pre-trained weights. No top means it excludes the fully connected layer it uses for classification.\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsiBCpQ1VvPp"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "# Initialize the base model.\n",
        "# Set the input shape and remove the dense layers.\n",
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
        "                                include_top = False, \n",
        "                                weights = None)\n",
        "\n",
        "# Set the weights file you downloaded into a variable\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "# Load the pre-trained weights you downloaded.\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Freeze the weights of the layers.\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1y2rEnqFaa9k"
      },
      "source": [
        "You can see the summary of the model below. You can see that it is a very deep network. You can then select up to which point of the network you want to use. As Laurence showed in the exercise, you will use up to `mixed_7` as your base model and add to that. This is because the original last layer might be too specialized in what it has learned so it might not translate well into your application. `mixed_7` on the other hand will be more generalized and you can start with that for your application. After the exercise, feel free to modify and use other layers to see what the results you get."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qeGP0Ust5kCR"
      },
      "outputs": [],
      "source": [
        "pre_trained_model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model: \"inception_v3\"\n",
        "__________________________________________________________________________________________________\n",
        " Layer (type)                   Output Shape         Param #     Connected to                     \n",
        "==================================================================================================\n",
        " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
        "                                )]                                                                \n",
        "                                                                                                  \n",
        " conv2d (Conv2D)                (None, 74, 74, 32)   864         ['input_1[0][0]']                \n",
        "                                                                                                  \n",
        " batch_normalization (BatchNorm  (None, 74, 74, 32)  96          ['conv2d[0][0]']                 \n",
        " alization)                                                                                       \n",
        "                                                                                                  \n",
        " activation (Activation)        (None, 74, 74, 32)   0           ['batch_normalization[0][0]']    \n",
        "                                                                                                  \n",
        " conv2d_1 (Conv2D)              (None, 72, 72, 32)   9216        ['activation[0][0]']             \n",
        "                                                                                                  \n",
        " batch_normalization_1 (BatchNo  (None, 72, 72, 32)  96          ['conv2d_1[0][0]']               \n",
        " rmalization)                                                                                     \n",
        "                                                                                                  \n",
        " activation_1 (Activation)      (None, 72, 72, 32)   0           ['batch_normalization_1[0][0]']  \n",
        "                                                                                                  \n",
        " conv2d_2 (Conv2D)              (None, 72, 72, 64)   18432       ['activation_1[0][0]']           \n",
        "                                                                                                  \n",
        " batch_normalization_2 (BatchNo  (None, 72, 72, 64)  192         ['conv2d_2[0][0]']               \n",
        " rmalization)                                                                                     \n",
        "                                                                                                  \n",
        " activation_2 (Activation)      (None, 72, 72, 64)   0           ['batch_normalization_2[0][0]']  \n",
        "                                                                                                  \n",
        " max_pooling2d (MaxPooling2D)   (None, 35, 35, 64)   0           ['activation_2[0][0]']           \n",
        "                                                                                                  \n",
        " conv2d_3 (Conv2D)              (None, 35, 35, 80)   5120        ['max_pooling2d[0][0]']          \n",
        "                                                                                                  \n",
        " batch_normalization_3 (BatchNo  (None, 35, 35, 80)  240         ['conv2d_3[0][0]']               \n",
        " rmalization)                                                                                     \n",
        "                                                                                                  \n",
        " activation_3 (Activation)      (None, 35, 35, 80)   0           ['batch_normalization_3[0][0]']  \n",
        "                                                                                                  \n",
        " conv2d_4 (Conv2D)              (None, 33, 33, 192)  138240      ['activation_3[0][0]']           \n",
        "                                                                                                  \n",
        " batch_normalization_4 (BatchNo  (None, 33, 33, 192)  576        ['conv2d_4[0][0]']               \n",
        " rmalization)                                                                                     \n",
        "                                                                                                  \n",
        " activation_4 (Activation)      (None, 33, 33, 192)  0           ['batch_normalization_4[0][0]']  \n",
        "                                                                                                  \n",
        " max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0          ['activation_4[0][0]']           \n",
        "                                                                                                  \n",
        " conv2d_8 (Conv2D)              (None, 16, 16, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
        "                                                                                                  \n",
        " batch_normalization_8 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_8[0][0]']               \n",
        " rmalization)                                                                                     \n",
        "                                                                                                  \n",
        " activation_8 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_8[0][0]']  \n",
        "                                                                                                  \n",
        " conv2d_6 (Conv2D)              (None, 16, 16, 48)   9216        ['max_pooling2d_1[0][0]']        \n",
        "                                                                                                  \n",
        " conv2d_9 (Conv2D)              (None, 16, 16, 96)   55296       ['activation_8[0][0]']           \n",
        "                                                                                                  \n",
        " batch_normalization_6 (BatchNo  (None, 16, 16, 48)  144         ['conv2d_6[0][0]']               \n",
        " rmalization)                                                                                     \n",
        "                                                                                                  \n",
        " batch_normalization_9 (BatchNo  (None, 16, 16, 96)  288         ['conv2d_9[0][0]']               \n",
        " rmalization)                                                                                     \n",
        "                                                                                                  \n",
        " activation_6 (Activation)      (None, 16, 16, 48)   0           ['batch_normalization_6[0][0]']  \n",
        "                                                                                                  \n",
        " activation_9 (Activation)      (None, 16, 16, 96)   0           ['batch_normalization_9[0][0]']  \n",
        "                                                                                                  \n",
        " average_pooling2d (AveragePool  (None, 16, 16, 192)  0          ['max_pooling2d_1[0][0]']        \n",
        " ing2D)                                                                                           \n",
        "                                                                                                  \n",
        " conv2d_5 (Conv2D)              (None, 16, 16, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
        "                                                                                                  \n",
        " conv2d_7 (Conv2D)              (None, 16, 16, 64)   76800       ['activation_6[0][0]']           \n",
        "                                                                                                  \n",
        " conv2d_10 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_9[0][0]']           \n",
        "                                                                                                  \n",
        " conv2d_11 (Conv2D)             (None, 16, 16, 32)   6144        ['average_pooling2d[0][0]']      \n",
        "                                                                                                  \n",
        " batch_normalization_5 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_5[0][0]']               \n",
        " rmalization)                                                                                     \n",
        "                                                                                                  \n",
        " batch_normalization_7 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_7[0][0]']               \n",
        " rmalization)                                                                                     \n",
        "                                                                                                  \n",
        " batch_normalization_10 (BatchN  (None, 16, 16, 96)  288         ['conv2d_10[0][0]']              \n",
        " ormalization)                                                                                    \n",
        "                                                                                                  \n",
        " batch_normalization_11 (BatchN  (None, 16, 16, 32)  96          ['conv2d_11[0][0]']              \n",
        " ormalization)                                                                                    \n",
        "                                                                                                  \n",
        " activation_5 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_5[0][0]']  \n",
        "                                                                                                  \n",
        " activation_7 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_7[0][0]']  \n",
        "                                                                                                  \n",
        " activation_10 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_10[0][0]'] \n",
        "                                                                                                  \n",
        " activation_11 (Activation)     (None, 16, 16, 32)   0           ['batch_normalization_11[0][0]'] \n",
        "                                                                                                  \n",
        " mixed0 (Concatenate)           (None, 16, 16, 256)  0           ['activation_5[0][0]',           \n",
        "                                                                  'activation_7[0][0]',           \n",
        "                                                                  'activation_10[0][0]',          \n",
        "                                                                  'activation_11[0][0]']          \n",
        "                                                                                                  \n",
        " conv2d_15 (Conv2D)             (None, 16, 16, 64)   16384       ['mixed0[0][0]']                 \n",
        "                                                                                                  \n",
        " batch_normalization_15 (BatchN  (None, 16, 16, 64)  192         ['conv2d_15[0][0]']              \n",
        " ormalization)                                                                                    \n",
        "                                                                                                  \n",
        " activation_15 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_15[0][0]'] \n",
        "                                                                                                  \n",
        " conv2d_13 (Conv2D)             (None, 16, 16, 48)   12288       ['mixed0[0][0]']                 \n",
        "                                                                                                  \n",
        " conv2d_16 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_15[0][0]']          \n",
        "                                                                                                  \n",
        " batch_normalization_13 (BatchN  (None, 16, 16, 48)  144         ['conv2d_13[0][0]']              \n",
        " ormalization)                                                                                    \n",
        "                                                                                                  \n",
        " batch_normalization_16 (BatchN  (None, 16, 16, 96)  288         ['conv2d_16[0][0]']              \n",
        " ormalization)                                                                                    \n",
        "                                                                                                  \n",
        " activation_13 (Activation)     (None, 16, 16, 48)   0           ['batch_normalization_13[0][0]'] \n",
        "                                                                                                  \n",
        " activation_16 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_16[0][0]'] \n",
        "                                                                                                  \n",
        " average_pooling2d_1 (AveragePo  (None, 16, 16, 256)  0          ['mixed0[0][0]']                 \n",
        " oling2D)                                                                                         \n",
        "                                                                                                  \n",
        " conv2d_12 (Conv2D)             (None, 16, 16, 64)   16384       ['mixed0[0][0]']                 \n",
        "                                                                                                  \n",
        " conv2d_14 (Conv2D)             (None, 16, 16, 64)   76800       ['activation_13[0][0]']          \n",
        "                                                                                                  \n",
        " conv2d_17 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_16[0][0]']          \n",
        "                                                                                                  \n",
        " conv2d_18 (Conv2D)             (None, 16, 16, 64)   16384       ['average_pooling2d_1[0][0]']    \n",
        "                                                                                                  \n",
        " batch_normalization_12 (BatchN  (None, 16, 16, 64)  192         ['conv2d_12[0][0]']              \n",
        " ormalization)                                                                                    \n",
        "                                                                                                  \n",
        " batch_normalization_14 (BatchN  (None, 16, 16, 64)  192         ['conv2d_14[0][0]']              \n",
        " ormalization)                                                                                    \n",
        "                                                                                                  \n",
        " batch_normalization_17 (BatchN  (None, 16, 16, 96)  288         ['conv2d_17[0][0]']              \n",
        " ormalization)                                                                                    \n",
        "                                                                                                  \n",
        " batch_normalization_18 (BatchN  (None, 16, 16, 64)  192         ['conv2d_18[0][0]']              \n",
        " ormalization)                                                                                    \n",
        "                                                                                                  \n",
        " activation_12 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_12[0][0]'] \n",
        "                                                                                                  \n",
        " activation_14 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_14[0][0]'] \n",
        "                                                                                                  \n",
        " activation_17 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_17[0][0]'] \n",
        "                                                                                                  \n",
        " activation_18 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_18[0][0]'] \n",
        "                                                                                                  \n",
        " mixed1 (Concatenate)           (None, 16, 16, 288)  0           ['activation_12[0][0]',          \n",
        "                                                                  'activation_14[0][0]',          \n",
        "                                                                  'activation_17[0][0]',          \n",
        "                                                                  'activation_18[0][0]']          \n",
        "                                                                  "
      ],
      "metadata": {
        "id": "texcls71u0Km"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDmGO9tg5iPc"
      },
      "outputs": [],
      "source": [
        "# Choose `mixed_7` as the last layer of your base model\n",
        "# model이 너무 deep 하니까 mixed_1 ~ 10 까지 있는 거를 mixed_7에서 끊어 버리기\n",
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "last layer output shape:  (None, 7, 7, 768)"
      ],
      "metadata": {
        "id": "JbABnf3bu2zb"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXT9SDMK7Ioa"
      },
      "source": [
        "## Add dense layers for your classifier\n",
        "\n",
        "Next, you will add dense layers to your model. These will be the layers that you will train and is tasked with recognizing cats and dogs. You will add a [Dropout](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout) layer as well to regularize the output and avoid overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMXb913pbvFg"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import RMSprop \n",
        "from tensorflow.keras import Model\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
        "\n",
        "# Append the dense network to the base model\n",
        "model = Model(pre_trained_model.input, x) \n",
        "\n",
        "# Print the model summary. See your dense network connected at the end.\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "                                                                                                 \n",
        " batch_normalization_61 (BatchN  (None, 7, 7, 192)   576         ['conv2d_61[0][0]']              \n",
        " ormalization)                                                                                    \n",
        "                                                                                                  \n",
        " batch_normalization_66 (BatchN  (None, 7, 7, 192)   576         ['conv2d_66[0][0]']              \n",
        " ormalization)                                                                                    \n",
        "                                                                                                  \n",
        " activation_61 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_61[0][0]'] \n",
        "                                                                                                  \n",
        " activation_66 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_66[0][0]'] \n",
        "                                                                                                  \n",
        " conv2d_62 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_61[0][0]']          \n",
        "                                                                                                  \n",
        " conv2d_67 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_66[0][0]']          \n",
        "                                                                                                  \n",
        " batch_normalization_62 (BatchN  (None, 7, 7, 192)   576         ['conv2d_62[0][0]']              \n",
        " ormalization)                                                                                    \n",
        "                                                                                                  \n",
        " batch_normalization_67 (BatchN  (None, 7, 7, 192)   576         ['conv2d_67[0][0]']              \n",
        " ormalization)                                                                                    \n",
        "                                                                                                  \n",
        " activation_62 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_62[0][0]'] \n",
        "                                                                                                  \n",
        " activation_67 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_67[0][0]'] \n",
        "                                                                                                  \n",
        " average_pooling2d_6 (AveragePo  (None, 7, 7, 768)   0           ['mixed6[0][0]']                 \n",
        " oling2D)                                                                                         \n",
        "                                                                                                  \n",
        " conv2d_60 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
        "                                                                                                  \n",
        " conv2d_63 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_62[0][0]']          \n",
        "                                                                                                  \n",
        " conv2d_68 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_67[0][0]']          \n",
        "                                                                                                  \n",
        " conv2d_69 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_6[0][0]']    \n",
        "                                                                                                  \n",
        " batch_normalization_60 (BatchN  (None, 7, 7, 192)   576         ['conv2d_60[0][0]']              \n",
        " ormalization)                                                                                    \n",
        "                                                                                                  \n",
        " batch_normalization_63 (BatchN  (None, 7, 7, 192)   576         ['conv2d_63[0][0]']              \n",
        " ormalization)                                                                                    \n",
        "                                                                                                  \n",
        " batch_normalization_68 (BatchN  (None, 7, 7, 192)   576         ['conv2d_68[0][0]']              \n",
        " ormalization)                                                                                    \n",
        "                                                                                                  \n",
        " batch_normalization_69 (BatchN  (None, 7, 7, 192)   576         ['conv2d_69[0][0]']              \n",
        " ormalization)                                                                                    \n",
        "                                                                                                  \n",
        " activation_60 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_60[0][0]'] \n",
        "                                                                                                  \n",
        " activation_63 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_63[0][0]'] \n",
        "                                                                                                  \n",
        " activation_68 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_68[0][0]'] \n",
        "                                                                                                  \n",
        " activation_69 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_69[0][0]'] \n",
        "                                                                                                  \n",
        " mixed7 (Concatenate)           (None, 7, 7, 768)    0           ['activation_60[0][0]',          \n",
        "                                                                  'activation_63[0][0]',          \n",
        "                                                                  'activation_68[0][0]',          \n",
        "                                                                  'activation_69[0][0]']          \n",
        "                                                                                                  \n",
        " flatten (Flatten)              (None, 37632)        0           ['mixed7[0][0]']                 \n",
        "                                                                                                  \n",
        " dense (Dense)                  (None, 1024)         38536192    ['flatten[0][0]']                \n",
        "                                                                                                  \n",
        " dropout (Dropout)              (None, 1024)         0           ['dense[0][0]']                  \n",
        "                                                                                                  \n",
        " dense_1 (Dense)                (None, 1)            1025        ['dropout[0][0]']                \n",
        "                                                                                                  \n",
        "==================================================================================================\n",
        "Total params: 47,512,481\n",
        "Trainable params: 38,537,217\n",
        "Non-trainable params: 8,975,264\n",
        "__________________________________________________________________________________________________"
      ],
      "metadata": {
        "id": "620E18huu7Jb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAwTTkWr56uC"
      },
      "outputs": [],
      "source": [
        "# Set the training parameters\n",
        "model.compile(optimizer = RMSprop(learning_rate=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYLGw_RO7Z_X"
      },
      "source": [
        "## Prepare the dataset\n",
        "\n",
        "Now you will prepare the dataset. This is basically the same code as the one you used in the data augmentation lab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4s8HckqGlnb"
      },
      "outputs": [],
      "source": [
        "# Download the dataset\n",
        "!wget https://storage.googleapis.com/tensorflow-1-public/course2/cats_and_dogs_filtered.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOV8jON3c3Jv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Extract the archive\n",
        "zip_ref = zipfile.ZipFile(\"./cats_and_dogs_filtered.zip\", 'r')\n",
        "zip_ref.extractall(\"tmp/\")\n",
        "zip_ref.close()\n",
        "\n",
        "# Define our example directories and files\n",
        "base_dir = 'tmp/cats_and_dogs_filtered'\n",
        "\n",
        "train_dir = os.path.join( base_dir, 'train')\n",
        "validation_dir = os.path.join( base_dir, 'validation')\n",
        "\n",
        "# Directory with training cat pictures\n",
        "train_cats_dir = os.path.join(train_dir, 'cats') \n",
        "\n",
        "# Directory with training dog pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs') \n",
        "\n",
        "# Directory with validation cat pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats') \n",
        "\n",
        "# Directory with validation dog pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'binary', \n",
        "                                                    target_size = (150, 150))     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
        "                                                          batch_size  = 20,\n",
        "                                                          class_mode  = 'binary', \n",
        "                                                          target_size = (150, 150))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Found 2000 images belonging to 2 classes.\n",
        "Found 1000 images belonging to 2 classes."
      ],
      "metadata": {
        "id": "SuPV6jYvu9UR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3m3S6AZb7h-B"
      },
      "source": [
        "## Train the model\n",
        "\n",
        "With that, you can now train the model. You will do 20 epochs and plot the results afterwards."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Blhq2MAUeyGA"
      },
      "outputs": [],
      "source": [
        "# Train the model.\n",
        "history = model.fit(\n",
        "            train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            steps_per_epoch = 100,\n",
        "            epochs = 20,\n",
        "            validation_steps = 50,\n",
        "            verbose = 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Epoch 1/20\n",
        "100/100 - 34s - loss: 0.3194 - accuracy: 0.8635 - val_loss: 0.1081 - val_accuracy: 0.9600 - 34s/epoch - 338ms/step\n",
        "Epoch 2/20\n",
        "100/100 - 18s - loss: 0.2358 - accuracy: 0.9095 - val_loss: 0.1065 - val_accuracy: 0.9610 - 18s/epoch - 185ms/step\n",
        "Epoch 3/20\n",
        "100/100 - 18s - loss: 0.2078 - accuracy: 0.9225 - val_loss: 0.1035 - val_accuracy: 0.9610 - 18s/epoch - 185ms/step\n",
        "Epoch 4/20\n",
        "100/100 - 19s - loss: 0.2003 - accuracy: 0.9235 - val_loss: 0.1412 - val_accuracy: 0.9580 - 19s/epoch - 190ms/step\n",
        "Epoch 5/20\n",
        "100/100 - 18s - loss: 0.1882 - accuracy: 0.9320 - val_loss: 0.1598 - val_accuracy: 0.9480 - 18s/epoch - 184ms/step\n",
        "Epoch 6/20\n",
        "100/100 - 18s - loss: 0.1741 - accuracy: 0.9340 - val_loss: 0.1188 - val_accuracy: 0.9660 - 18s/epoch - 183ms/step\n",
        "Epoch 7/20\n",
        "100/100 - 18s - loss: 0.1539 - accuracy: 0.9435 - val_loss: 0.1094 - val_accuracy: 0.9690 - 18s/epoch - 183ms/step\n",
        "Epoch 8/20\n",
        "100/100 - 18s - loss: 0.1523 - accuracy: 0.9500 - val_loss: 0.1479 - val_accuracy: 0.9540 - 18s/epoch - 182ms/step\n",
        "Epoch 9/20\n",
        "100/100 - 18s - loss: 0.1609 - accuracy: 0.9445 - val_loss: 0.1299 - val_accuracy: 0.9630 - 18s/epoch - 184ms/step\n",
        "Epoch 10/20\n",
        "100/100 - 18s - loss: 0.1574 - accuracy: 0.9430 - val_loss: 0.1164 - val_accuracy: 0.9630 - 18s/epoch - 181ms/step\n",
        "Epoch 11/20\n",
        "100/100 - 18s - loss: 0.1589 - accuracy: 0.9480 - val_loss: 0.1179 - val_accuracy: 0.9640 - 18s/epoch - 183ms/step\n",
        "Epoch 12/20\n",
        "100/100 - 18s - loss: 0.1377 - accuracy: 0.9525 - val_loss: 0.1553 - val_accuracy: 0.9660 - 18s/epoch - 184ms/step\n",
        "Epoch 13/20\n",
        "100/100 - 18s - loss: 0.1434 - accuracy: 0.9490 - val_loss: 0.1491 - val_accuracy: 0.9610 - 18s/epoch - 183ms/step\n",
        "Epoch 14/20\n",
        "100/100 - 18s - loss: 0.1625 - accuracy: 0.9500 - val_loss: 0.1360 - val_accuracy: 0.9640 - 18s/epoch - 182ms/step\n",
        "Epoch 15/20\n",
        "100/100 - 18s - loss: 0.1410 - accuracy: 0.9495 - val_loss: 0.1398 - val_accuracy: 0.9610 - 18s/epoch - 184ms/step\n",
        "Epoch 16/20\n",
        "100/100 - 18s - loss: 0.1401 - accuracy: 0.9510 - val_loss: 0.1367 - val_accuracy: 0.9650 - 18s/epoch - 183ms/step\n",
        "Epoch 17/20\n",
        "100/100 - 18s - loss: 0.1378 - accuracy: 0.9535 - val_loss: 0.1467 - val_accuracy: 0.9680 - 18s/epoch - 181ms/step\n",
        "Epoch 18/20\n",
        "100/100 - 20s - loss: 0.1460 - accuracy: 0.9525 - val_loss: 0.1638 - val_accuracy: 0.9580 - 20s/epoch - 199ms/step\n",
        "Epoch 19/20\n",
        "100/100 - 19s - loss: 0.1237 - accuracy: 0.9560 - val_loss: 0.1300 - val_accuracy: 0.9670 - 19s/epoch - 192ms/step\n",
        "Epoch 20/20\n",
        "100/100 - 18s - loss: 0.1296 - accuracy: 0.9550 - val_loss: 0.1390 - val_accuracy: 0.9720 - 18s/epoch - 183ms/step"
      ],
      "metadata": {
        "id": "bhwiKPrmu-sT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwcB2bPj7lIx"
      },
      "source": [
        "## Evaluate the results\n",
        "\n",
        "You will use the same code to plot the results. As you can see, the validation accuracy is also trending upwards as your training accuracy improves. This is a good sign that your model is no longer overfitting!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2Fp6Se9rKuL"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)\n"
      ],
      "metadata": {
        "id": "lWq5w3iZu_-Z"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "C2_W3_Lab_1_transfer_learning.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}