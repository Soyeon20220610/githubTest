{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ob-n2Y1l15ro"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/https-deeplearning-ai/tensorflow-1-public/blob/master/C3/W4/ungraded_labs/C3_W4_Lab_2_irish_lyrics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqIxQYm8h06Z"
      },
      "source": [
        "# Ungraded Lab: Generating Text from Irish Lyrics\n",
        "\n",
        "In the previous lab, you trained a model on just a single song. You might have found that the output text can quickly become gibberish or repetitive. Even if you tweak the hyperparameters, the model will still be limited by its vocabulary of only 263 words. The model will be more flexible if you train it on a much larger corpus and that's what you'll be doing in this lab. You will use lyrics from more Irish songs then see how the generated text looks like. You will also see how this impacts the process from data preparation to model training. Let's get started!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wb1mfOvch4Sv"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOwsuGQQY9OL"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np \n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmBFI788pOXx"
      },
      "source": [
        "## Building the Word Vocabulary\n",
        "\n",
        "You will first download the lyrics dataset. These will be from a compilation of traditional Irish songs and you can see them [here](https://github.com/https-deeplearning-ai/tensorflow-1-public/blob/main/C3/W4/misc/Laurences_generated_poetry.txt). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pylt5qZYsWPh"
      },
      "outputs": [],
      "source": [
        "# Download the dataset\n",
        "!wget https://storage.googleapis.com/tensorflow-1-public/course3/irish-lyrics-eof.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-v6JYQGNPXCW"
      },
      "source": [
        "Next, you will lowercase and split the plain text into a list of sentences:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKOO7DFCPX3L"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "data = open('./irish-lyrics-eof.txt').read()\n",
        "\n",
        "# Lowercase and split the text\n",
        "corpus = data.lower().split(\"\\n\")\n",
        "\n",
        "# Preview the result\n",
        "print(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ['come all ye maidens young and fair', 'and you that are blooming in your prime', 'always beware and keep your garden fair', 'let no man steal away your thyme', ' ' ]"
      ],
      "metadata": {
        "id": "n7-7jBAv2Sh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkP2CP0qP8RD"
      },
      "source": [
        "From here, you can initialize the `Tokenizer` class and generate the word index dictionary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRnDnCW-Z7qv"
      },
      "outputs": [],
      "source": [
        "# Initialize the Tokenizer class\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "# Generate the word index dictionary\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "\n",
        "# Define the total words. You add 1 for the index `0` which is just the padding token.\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "print(f'word index dictionary: {tokenizer.word_index}')\n",
        "print(f'total words: {total_words}')\n",
        "\n",
        "\n",
        "# word index dictionary: {'the': 1, 'and': 2, 'i': 3, 'to': 4, 'a': 5, 'of': 6, 'my': 7, 'in': 8, 'me': 9, 'for': 10, 'you': 11, 'all': 12,\n",
        "# total words: 2690\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JK29FzZ7QW-4"
      },
      "source": [
        "## Preprocessing the Dataset\n",
        "\n",
        "Next, you will generate the inputs and labels for your model. The process will be identical to the previous lab. The `xs` or inputs to the model will be padded sequences, while the `ys` or labels are one-hot encoded arrays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "soPGVheskaQP"
      },
      "outputs": [],
      "source": [
        "# Initialize the sequences list\n",
        "input_sequences = []\n",
        "\n",
        "# Loop over every line\n",
        "for line in corpus:\n",
        "\n",
        "\t# Tokenize the current line\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\n",
        "\t# Loop over the line several times to generate the subphrases\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\t\n",
        "\t\t# Generate the subphrase\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\n",
        "\t\t# Append the subphrase to the sequences list\n",
        "\t\tinput_sequences.append(n_gram_sequence)\n",
        "\n",
        "# Get the length of the longest line\n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "\n",
        "# Pad all sequences\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# Create inputs and label by splitting the last token in the subphrases\n",
        "xs, labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "\n",
        "# Convert the label into one-hot arrays\n",
        "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmWHCO0dQGlZ"
      },
      "source": [
        "You can then print some of the examples as a sanity check."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJtwVB2NbOAP"
      },
      "outputs": [],
      "source": [
        "# Get sample sentence\n",
        "sentence = corpus[0].split()\n",
        "print(f'sample sentence: {sentence}')\n",
        "\n",
        "# Initialize token list\n",
        "token_list = []\n",
        "\n",
        "# Look up the indices of each word and append to the list\n",
        "for word in sentence: \n",
        "  token_list.append(tokenizer.word_index[word])\n",
        "\n",
        "# Print the token list\n",
        "print(token_list)\n",
        "\n",
        "\n",
        "# sample sentence: ['come', 'all', 'ye', 'maidens', 'young', 'and', 'fair']\n",
        "# [51, 12, 96, 1217, 48, 2, 69]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMr6kKfzROlW"
      },
      "outputs": [],
      "source": [
        "# Pick element\n",
        "elem_number = 5\n",
        "\n",
        "# Print token list and phrase\n",
        "print(f'token list: {xs[elem_number]}')\n",
        "print(f'decoded to text: {tokenizer.sequences_to_texts([xs[elem_number]])}')\n",
        "\n",
        "# Print label\n",
        "print(f'one-hot label: {ys[elem_number]}')\n",
        "print(f'index of label: {np.argmax(ys[elem_number])}')\n",
        "\n",
        "# token list: [   0    0    0    0    0    0    0    0    0   51   12   96 1217   48  2]\n",
        "# decoded to text: ['come all ye maidens young and']\n",
        "# one-hot label: [0. 0. 0. ... 0. 0. 0.]\n",
        "# index of label: 69  다음에 올 단어의 인덱스"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49Cv68JOakwv"
      },
      "outputs": [],
      "source": [
        "# Pick element\n",
        "elem_number = 4\n",
        "\n",
        "# Print token list and phrase\n",
        "print(f'token list: {xs[elem_number]}')\n",
        "print(f'decoded to text: {tokenizer.sequences_to_texts([xs[elem_number]])}')\n",
        "\n",
        "# Print label\n",
        "print(f'one-hot label: {ys[elem_number]}')\n",
        "print(f'index of label: {np.argmax(ys[elem_number])}')\n",
        "\n",
        "\n",
        "# token list: [   0    0    0    0    0    0    0    0    0    0   51   12   96 1217\n",
        "#    48]\n",
        "# decoded to text: ['come all ye maidens young']\n",
        "# one-hot label: [0. 0. 1. ... 0. 0. 0.]\n",
        "# index of label: 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKWWUZm5VPG9"
      },
      "source": [
        "## Build and compile the Model\n",
        "\n",
        "Next, you will build and compile the model. We placed some of the hyperparameters at the top of the code cell so you can easily tweak it later if you want."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9vH8Y59ajYL"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "embedding_dim = 100\n",
        "lstm_units = 150\n",
        "learning_rate = 0.01\n",
        "\n",
        "# Build the model\n",
        "model = Sequential([\n",
        "          Embedding(total_words, embedding_dim, input_length=max_sequence_len-1),\n",
        "          Bidirectional(LSTM(lstm_units)),\n",
        "          Dense(total_words, activation='softmax')\n",
        "])\n",
        "\n",
        "# Use categorical crossentropy because this is a multi-class problem\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy', \n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), \n",
        "    metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpI0d9cfR43c"
      },
      "source": [
        "## Train the model\n",
        "\n",
        "From the model summary above, you'll notice that the number of trainable params is much larger than the one in the previous lab. Consequently, that usually means a slower training time. It will take roughly 7 seconds per epoch with the GPU enabled in Colab and you'll reach around 76% accuracy after 100 epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nc4zC7C4jJpN"
      },
      "outputs": [],
      "source": [
        "epochs = 100\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(xs, ys, epochs=epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Epoch 100/100\n",
        "377/377 [==============================] - 3s 8ms/step - loss: 0.8050 - accuracy: 0.7841"
      ],
      "metadata": {
        "id": "X2oTkZfA7lku"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgAzLnLATFts"
      },
      "source": [
        "You can visualize the accuracy below to see how it fluctuates as the training progresses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3YXGelKThoTT"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot utility\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.show()\n",
        "\n",
        "# Visualize the accuracy\n",
        "plot_graphs(history, 'accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "k8dKNlV87m84"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gxKIcvGTUnw"
      },
      "source": [
        "## Generating Text\n",
        "\n",
        "Now you can let the model make its own songs or poetry! Because it is trained on a much larger corpus, the results below should contain less repetitions as before. The code below picks the next word based on the highest probability output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Vc6PHgxa6Hm"
      },
      "outputs": [],
      "source": [
        "# Define seed text\n",
        "seed_text = \"help me obi-wan kinobi youre my only hope\"\n",
        "\n",
        "# Define total words to predict\n",
        "next_words = 100\n",
        "\n",
        "# Loop until desired length is reached\n",
        "for _ in range(next_words):\n",
        "\n",
        "\t# Convert the seed text to a token sequence\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\n",
        "\t# Pad the sequence\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\t\n",
        "\t# Feed to the model and get the probabilities for each index\n",
        "\tprobabilities = model.predict(token_list)\n",
        "\n",
        "\t# Get the index with the highest probability\n",
        "\tpredicted = np.argmax(probabilities, axis=-1)[0]\n",
        "\n",
        "\t# Ignore if index is 0 because that is just the padding.\n",
        "\tif predicted != 0:\n",
        "\t\t\n",
        "\t\t# Look up the word associated with the index. \n",
        "\t\toutput_word = tokenizer.index_word[predicted]\n",
        "\n",
        "\t\t# Combine with the seed text\n",
        "\t\tseed_text += \" \" + output_word\n",
        "\n",
        "# Print the result\t\n",
        "print(seed_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "help me obi-wan kinobi youre my only hope said have heard the town of athy more i love sinking funds to sinking strangely alone that i love i love twill i gone and i keep gone i couldnt shoot gone i couldnt shoot the sinking funds when gone more sinking note when love i love gone i gone love again he rocky when volunteers sinking eyes gone i love i love i back back against the rocky road to sea twilight rebel love sinking eyes i love i right i love i love best i right to darlin name back right darlin saw i love again ache pair\n"
      ],
      "metadata": {
        "id": "q92h4_c77o0l"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHtrtAFAT6tn"
      },
      "source": [
        "Here again is the code that gets the top 3 predictions and picks one at random."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJfzKm-8mVKD"
      },
      "outputs": [],
      "source": [
        "# Define seed text\n",
        "seed_text = \"help me obi-wan kinobi youre my only hope\"\n",
        "\n",
        "# Define total words to predict\n",
        "next_words = 100\n",
        "\n",
        "# Loop until desired length is reached\n",
        "for _ in range(next_words):\n",
        "\n",
        "\t# Convert the seed text to a token sequence\n",
        "  token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\n",
        "\t# Pad the sequence\n",
        "  token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\t\n",
        "\t# Feed to the model and get the probabilities for each index\n",
        "  probabilities = model.predict(token_list)\n",
        "\n",
        "  # Pick a random number from [1,2,3]\n",
        "  choice = np.random.choice([1,2,3])\n",
        "\t\n",
        "  # Sort the probabilities in ascending order \n",
        "  # and get the random choice from the end of the array\n",
        "  predicted = np.argsort(probabilities)[0][-choice]\n",
        "\n",
        "\t# Ignore if index is 0 because that is just the padding.\n",
        "  if predicted != 0:\n",
        "\t\t\n",
        "\t\t# Look up the word associated with the index. \n",
        "\t  output_word = tokenizer.index_word[predicted]\n",
        "\n",
        "\t\t# Combine with the seed text\n",
        "\t  seed_text += \" \" + output_word\n",
        "\n",
        "# Print the result\t\n",
        "print(seed_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "help me obi-wan kinobi youre my only hope in my true are they were eyes glisten love i right love paddy of sinking carried saw love them redeem gone i gone again hat i right forth when run gone i couldnt new gone eyes love best love than i a sinking asunder when i i thinking gone as hat i sat rink rink love easy gone by seen came love to sea breeze love me though love and i drew laughs i vermin i variety gone love again fulfill stranger sinking right in i ever should make bantry pearse sinking bride love i lovd i remember i walked\n"
      ],
      "metadata": {
        "id": "xULVWDbk7qiq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DP0--sdMUJ_k"
      },
      "source": [
        "## Wrap Up\n",
        "\n",
        "This lab shows the effect of having a larger dataset to train your text generation model. As expected, this will take a longer time to prepare and train but the output will less likely become repetitive or gibberish. Try to tweak the hyperparameters and see if you get better results. You can also find some other text datasets and use it to train the model here.  "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "C3_W4_Lab_2_irish_lyrics.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}